main start at this time 1713059114.9115696
-----------------------------------------before load data 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

the output layer 
self.num_batch (get_in_degree_bucketing) 25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  25
25
25
[0.14765617268338813, 0.12872081899253363, 0.10201119407088112, 0.08049174739666377, 0.06841798528716421, 0.05352921124685236, 0.04447938773490505, 0.038178599311641616, 0.03272451369569281, 0.028578968781957533, 0.02422449720148228, 0.02129952386712264, 0.01820960842744197, 0.01576846526869069, 0.014174024917254044, 0.012216711934111127, 0.011326024565377553, 0.010424341056289243, 0.009192773336558867, 0.00887388526627154, 0.007884232634345345, 0.006113854037232931, 0.005706996844107718, 0.005772973686236131, 0.10402348775579771]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.007999658584594727
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.0001342296600341797
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.599172830581665
self.buckets_partition() spend  sec:  0.008145332336425781
input layer
redundancy ratio #input/#seeds/degree
4.56680071492404
3.1914402870322913
2.8342855089648236
2.6986680327868853
2.5762134361941498
2.63191591344837
2.63150273706516
2.6192396313364057
2.6360887096774195
2.655713736052328
2.6916601328766556
2.7846325933574256
2.840626161278335
2.9388324367403866
2.9713990173260925
3.029027902790279
3.052541404911479
3.0474097515236753
3.2010828506673383
3.09361833952912
3.2032277346084874
3.4606769130150425
3.5304515372371617
3.4235714285714285
0.5199661733615222
layer  0
{1: 13428, 2: 1514, 3: 1424, 4: 1036, 5: 890, 6: 712, 7: 552, 8: 442, 9: 392, 10: 3685}
layer  1
{1: 13428}

layer  0
{1: 1525, 2: 12162, 3: 2064, 4: 1606, 5: 1420, 6: 1110, 7: 954, 8: 766, 9: 639, 10: 5875}
layer  1
{2: 11706}

layer  0
{1: 1582, 2: 2280, 3: 9755, 4: 1987, 5: 1726, 6: 1356, 7: 1163, 8: 966, 9: 828, 10: 7423}
layer  1
{3: 9277}

layer  0
{1: 1251, 2: 1864, 3: 2112, 4: 7759, 5: 1867, 6: 1529, 7: 1277, 8: 1115, 9: 912, 10: 8511}
layer  1
{4: 7320}

layer  0
{1: 1076, 2: 1735, 3: 2034, 4: 2003, 5: 6670, 6: 1576, 7: 1397, 8: 1196, 9: 1033, 10: 9513}
layer  1
{5: 6222}

layer  0
{1: 904, 2: 1401, 3: 1546, 4: 1745, 5: 1668, 6: 5231, 7: 1341, 8: 1178, 9: 993, 10: 9999}
layer  1
{6: 4868}

layer  0
{1: 724, 2: 1210, 3: 1421, 4: 1525, 5: 1541, 6: 1424, 7: 4368, 8: 1150, 9: 1022, 10: 10305}
layer  1
{7: 4045}

layer  0
{1: 615, 2: 990, 3: 1214, 4: 1372, 5: 1431, 6: 1273, 7: 1220, 8: 3789, 9: 1041, 10: 10789}
layer  1
{8: 3472}

layer  0
{1: 519, 2: 890, 3: 1092, 4: 1243, 5: 1253, 6: 1154, 7: 1128, 8: 1065, 9: 3251, 10: 10836}
layer  1
{9: 2976}

layer  0
{1: 457, 2: 779, 3: 940, 4: 1085, 5: 1115, 6: 1112, 7: 1051, 8: 1002, 9: 910, 10: 13099}
layer  1
{10: 2599}

layer  0
{1: 373, 2: 610, 3: 837, 4: 910, 5: 994, 6: 944, 7: 952, 8: 949, 9: 857, 10: 12460}
layer  1
{11: 2203}

layer  0
{1: 345, 2: 621, 3: 789, 4: 892, 5: 968, 6: 980, 7: 898, 8: 920, 9: 813, 10: 12180}
layer  1
{12: 1937}

layer  0
{1: 357, 2: 566, 3: 685, 4: 775, 5: 803, 6: 793, 7: 797, 8: 819, 9: 733, 10: 11507}
layer  1
{13: 1656}

layer  0
{1: 279, 2: 460, 3: 602, 4: 672, 5: 713, 6: 780, 7: 730, 8: 740, 9: 657, 10: 11030}
layer  1
{14: 1434}

layer  0
{1: 280, 2: 457, 3: 563, 4: 621, 5: 651, 6: 667, 7: 663, 8: 707, 9: 659, 10: 10813}
layer  1
{15: 1289}

layer  0
{1: 195, 2: 356, 3: 454, 4: 544, 5: 576, 6: 610, 7: 579, 8: 589, 9: 572, 10: 10217}
layer  1
{16: 1111}

layer  0
{1: 205, 2: 377, 3: 470, 4: 546, 5: 572, 6: 590, 7: 564, 8: 547, 9: 612, 10: 10194}
layer  1
{17: 1030}

layer  0
{1: 204, 2: 315, 3: 373, 4: 487, 5: 485, 6: 570, 7: 536, 8: 542, 9: 542, 10: 9940}
layer  1
{18: 948}

layer  0
{1: 199, 2: 299, 3: 387, 4: 450, 5: 489, 6: 514, 7: 507, 8: 514, 9: 532, 10: 9413}
layer  1
{19: 836}

layer  0
{1: 143, 2: 272, 3: 351, 4: 424, 5: 444, 6: 496, 7: 474, 8: 532, 9: 494, 10: 9707}
layer  1
{20: 807}

layer  0
{1: 203, 2: 288, 3: 371, 4: 397, 5: 448, 6: 453, 7: 433, 8: 441, 9: 491, 10: 9029}
layer  1
{21: 717}

layer  0
{1: 105, 2: 206, 3: 255, 4: 308, 5: 307, 6: 349, 7: 377, 8: 386, 9: 342, 10: 7803}
layer  1
{22: 556}

layer  0
{1: 125, 2: 220, 3: 284, 4: 287, 5: 318, 6: 324, 7: 350, 8: 357, 9: 353, 10: 7787}
layer  1
{23: 519}

layer  0
{1: 115, 2: 197, 3: 259, 4: 313, 5: 337, 6: 338, 7: 332, 8: 333, 9: 373, 10: 7982}
layer  1
{24: 525}

layer  0
{1: 1507, 2: 2532, 3: 3153, 4: 3513, 5: 3655, 6: 3710, 7: 3684, 8: 3608, 9: 3437, 10: 51918}
layer  1
{25: 9460}

data_dict
[[{1: 13428, 2: 1514, 3: 1424, 4: 1036, 5: 890, 6: 712, 7: 552, 8: 442, 9: 392, 10: 3685}, {1: 13428}], [{1: 1525, 2: 12162, 3: 2064, 4: 1606, 5: 1420, 6: 1110, 7: 954, 8: 766, 9: 639, 10: 5875}, {2: 11706}], [{1: 1582, 2: 2280, 3: 9755, 4: 1987, 5: 1726, 6: 1356, 7: 1163, 8: 966, 9: 828, 10: 7423}, {3: 9277}], [{1: 1251, 2: 1864, 3: 2112, 4: 7759, 5: 1867, 6: 1529, 7: 1277, 8: 1115, 9: 912, 10: 8511}, {4: 7320}], [{1: 1076, 2: 1735, 3: 2034, 4: 2003, 5: 6670, 6: 1576, 7: 1397, 8: 1196, 9: 1033, 10: 9513}, {5: 6222}], [{1: 904, 2: 1401, 3: 1546, 4: 1745, 5: 1668, 6: 5231, 7: 1341, 8: 1178, 9: 993, 10: 9999}, {6: 4868}], [{1: 724, 2: 1210, 3: 1421, 4: 1525, 5: 1541, 6: 1424, 7: 4368, 8: 1150, 9: 1022, 10: 10305}, {7: 4045}], [{1: 615, 2: 990, 3: 1214, 4: 1372, 5: 1431, 6: 1273, 7: 1220, 8: 3789, 9: 1041, 10: 10789}, {8: 3472}], [{1: 519, 2: 890, 3: 1092, 4: 1243, 5: 1253, 6: 1154, 7: 1128, 8: 1065, 9: 3251, 10: 10836}, {9: 2976}], [{1: 457, 2: 779, 3: 940, 4: 1085, 5: 1115, 6: 1112, 7: 1051, 8: 1002, 9: 910, 10: 13099}, {10: 2599}], [{1: 373, 2: 610, 3: 837, 4: 910, 5: 994, 6: 944, 7: 952, 8: 949, 9: 857, 10: 12460}, {11: 2203}], [{1: 345, 2: 621, 3: 789, 4: 892, 5: 968, 6: 980, 7: 898, 8: 920, 9: 813, 10: 12180}, {12: 1937}], [{1: 357, 2: 566, 3: 685, 4: 775, 5: 803, 6: 793, 7: 797, 8: 819, 9: 733, 10: 11507}, {13: 1656}], [{1: 279, 2: 460, 3: 602, 4: 672, 5: 713, 6: 780, 7: 730, 8: 740, 9: 657, 10: 11030}, {14: 1434}], [{1: 280, 2: 457, 3: 563, 4: 621, 5: 651, 6: 667, 7: 663, 8: 707, 9: 659, 10: 10813}, {15: 1289}], [{1: 195, 2: 356, 3: 454, 4: 544, 5: 576, 6: 610, 7: 579, 8: 589, 9: 572, 10: 10217}, {16: 1111}], [{1: 205, 2: 377, 3: 470, 4: 546, 5: 572, 6: 590, 7: 564, 8: 547, 9: 612, 10: 10194}, {17: 1030}], [{1: 204, 2: 315, 3: 373, 4: 487, 5: 485, 6: 570, 7: 536, 8: 542, 9: 542, 10: 9940}, {18: 948}], [{1: 199, 2: 299, 3: 387, 4: 450, 5: 489, 6: 514, 7: 507, 8: 514, 9: 532, 10: 9413}, {19: 836}], [{1: 143, 2: 272, 3: 351, 4: 424, 5: 444, 6: 496, 7: 474, 8: 532, 9: 494, 10: 9707}, {20: 807}], [{1: 203, 2: 288, 3: 371, 4: 397, 5: 448, 6: 453, 7: 433, 8: 441, 9: 491, 10: 9029}, {21: 717}], [{1: 105, 2: 206, 3: 255, 4: 308, 5: 307, 6: 349, 7: 377, 8: 386, 9: 342, 10: 7803}, {22: 556}], [{1: 125, 2: 220, 3: 284, 4: 287, 5: 318, 6: 324, 7: 350, 8: 357, 9: 353, 10: 7787}, {23: 519}], [{1: 115, 2: 197, 3: 259, 4: 313, 5: 337, 6: 338, 7: 332, 8: 333, 9: 373, 10: 7982}, {24: 525}], [{1: 1507, 2: 2532, 3: 3153, 4: 3513, 5: 3655, 6: 3710, 7: 3684, 8: 3608, 9: 3437, 10: 51918}, {25: 9460}]]
estimated_mem_dict
{0: 1.4676693677902222, 1: 2.4761542081832886, 2: 2.968276262283325, 3: 3.164096027612686, 4: 3.3782851696014404, 5: 3.2312432527542114, 6: 3.163166642189026, 7: 3.1318494379520416, 8: 3.0311587750911713, 9: 2.964596003293991, 10: 2.7700038850307465, 11: 2.675661474466324, 12: 2.47877499461174, 13: 2.3252018988132477, 14: 2.2461649775505066, 15: 2.0726383924484253, 16: 2.0520736277103424, 17: 1.9905166625976562, 18: 1.8676097989082336, 19: 1.8976333737373352, 20: 1.7695181965827942, 21: 1.4633708596229553, 22: 1.4395877122879028, 23: 1.4982819557189941, 24: 20.767955482006073}

 MM estimated memory/GB degree 0: 1.4676693677902222 * 4.56680071492404*0.226
 MM estimated memory/GB degree 1: 2.4761542081832886 * 3.1914402870322913*0.226
 MM estimated memory/GB degree 2: 2.968276262283325 * 2.8342855089648236*0.226
 MM estimated memory/GB degree 3: 3.164096027612686 * 2.6986680327868853*0.226
 MM estimated memory/GB degree 4: 3.3782851696014404 * 2.5762134361941498*0.226
 MM estimated memory/GB degree 5: 3.2312432527542114 * 2.63191591344837*0.226
 MM estimated memory/GB degree 6: 3.163166642189026 * 2.63150273706516*0.226
 MM estimated memory/GB degree 7: 3.1318494379520416 * 2.6192396313364057*0.226
 MM estimated memory/GB degree 8: 3.0311587750911713 * 2.6360887096774195*0.226
 MM estimated memory/GB degree 9: 2.964596003293991 * 2.655713736052328*0.226
 MM estimated memory/GB degree 10: 2.7700038850307465 * 2.6916601328766556*0.226
 MM estimated memory/GB degree 11: 2.675661474466324 * 2.7846325933574256*0.226
 MM estimated memory/GB degree 12: 2.47877499461174 * 2.840626161278335*0.226
 MM estimated memory/GB degree 13: 2.3252018988132477 * 2.9388324367403866*0.226
 MM estimated memory/GB degree 14: 2.2461649775505066 * 2.9713990173260925*0.226
 MM estimated memory/GB degree 15: 2.0726383924484253 * 3.029027902790279*0.226
 MM estimated memory/GB degree 16: 2.0520736277103424 * 3.052541404911479*0.226
 MM estimated memory/GB degree 17: 1.9905166625976562 * 3.0474097515236753*0.226
 MM estimated memory/GB degree 18: 1.8676097989082336 * 3.2010828506673383*0.226
 MM estimated memory/GB degree 19: 1.8976333737373352 * 3.09361833952912*0.226
 MM estimated memory/GB degree 20: 1.7695181965827942 * 3.2032277346084874*0.226
 MM estimated memory/GB degree 21: 1.4633708596229553 * 3.4606769130150425*0.226
 MM estimated memory/GB degree 22: 1.4395877122879028 * 3.5304515372371617*0.226
 MM estimated memory/GB degree 23: 1.4982819557189941 * 3.4235714285714285*0.226
 MM estimated memory/GB degree 24: 20.767955482006073 * 0.5199661733615222*0.226

modified_estimated_mem_list [:-1]
[1.514777095089809, 1.785964615099556, 1.901324981675421, 1.9297789253393096, 1.9669195038203218, 1.921985481395105, 1.881197258937281, 1.8538925018013557, 1.805831173882189, 1.7793247420813727, 1.6850354397066607, 1.6838659180332751, 1.591327720061368, 1.5443436002578126, 1.5083810439923644, 1.4188459722252713, 1.4156729754798756, 1.3708978947265238, 1.3511124559792935, 1.3267450699133723, 1.2810063667065785, 1.1445213472912072, 1.1486211913146094, 1.1592614167928696]
sum [:-1] =  37.97063469160281

modified_estimated_mem_list [-1]
2.440491360957779
modified_mem [1, fanout-1]: 
[1.514777095089809, 1.785964615099556, 1.901324981675421, 1.9297789253393096, 1.9669195038203218, 1.921985481395105, 1.881197258937281, 1.8538925018013557, 1.805831173882189, 1.7793247420813727, 1.6850354397066607, 1.6838659180332751, 1.591327720061368, 1.5443436002578126, 1.5083810439923644, 1.4188459722252713, 1.4156729754798756, 1.3708978947265238, 1.3511124559792935, 1.3267450699133723, 1.2810063667065785, 1.1445213472912072, 1.1486211913146094, 1.1592614167928696]

mem size of fanout degree bucket by formula (GB):  20.767955482006073
the modified memory estimation spend (sec) 0.08092546463012695
the time of number of fanout blocks generation (sec) 1.5078413486480713
the time dict collection (sec) 0.08024191856384277
the time estimate mem (sec) 0.0003476142883300781
