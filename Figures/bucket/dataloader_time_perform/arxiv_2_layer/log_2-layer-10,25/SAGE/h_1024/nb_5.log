main start at this time 1713059490.5503426
-----------------------------------------before load data 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.45330238342285156
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0007102489471435547
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.00825357437133789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4542500972747803
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.6042923927307129
self.buckets_partition() spend  sec:  0.4625282287597656
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 0.63818359375 GB
    Memory Allocated: 0.10207128524780273  GigaBytes
Max Memory Allocated: 0.10207128524780273  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 17.34326171875 GB
    Memory Allocated: 15.412543773651123  GigaBytes
Max Memory Allocated: 16.199524879455566  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 17.34326171875 GB
    Memory Allocated: 15.414819240570068  GigaBytes
Max Memory Allocated: 16.199524879455566  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 18.00537109375 GB
    Memory Allocated: 0.16458559036254883  GigaBytes
Max Memory Allocated: 16.199524879455566  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.98779296875 GB
    Memory Allocated: 15.565165519714355  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.98779296875 GB
    Memory Allocated: 15.570262432098389  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.61474609375 GB
    Memory Allocated: 0.16985750198364258  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.61669921875 GB
    Memory Allocated: 14.740196228027344  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.61669921875 GB
    Memory Allocated: 14.743988037109375  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.20849609375 GB
    Memory Allocated: 0.1643376350402832  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.21826171875 GB
    Memory Allocated: 14.327200889587402  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.21826171875 GB
    Memory Allocated: 14.328864574432373  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.21826171875 GB
    Memory Allocated: 0.1617884635925293  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 10.310794830322266  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 10.312275409698486  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 0.20034217834472656  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.7765719890594482
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.4469478130340576
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0003750324249267578
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0071375370025634766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.44745826721191406
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5846529006958008
self.buckets_partition() spend  sec:  0.4546165466308594
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 0.18814611434936523  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 15.48247480392456  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 15.482346057891846  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 0.23135042190551758  GigaBytes
Max Memory Allocated: 16.434001922607422  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 15.650475978851318  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 15.655572891235352  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 0.23644208908081055  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 14.802995681762695  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 14.806787490844727  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 0.23044824600219727  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 14.389230728149414  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22021484375 GB
    Memory Allocated: 14.390730381011963  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22216796875 GB
    Memory Allocated: 0.22844791412353516  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.359159469604492  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.360640048980713  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2010517120361328  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.191554307937622
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.3001680374145508
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0004360675811767578
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.007344722747802734
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.3007471561431885
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.44042420387268066
self.buckets_partition() spend  sec:  0.3081192970275879
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.1881084442138672  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.475350379943848  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.475081443786621  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23084402084350586  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.633092403411865  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.638174057006836  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2359142303466797  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.83034372329712  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.83413553237915  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23044729232788086  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.351285934448242  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.352949619293213  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2279372215270996  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.380060195922852  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.381454467773438  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.200653076171875  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.611082077026367
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.4715843200683594
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0004756450653076172
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.007354259490966797
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.472179651260376
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.6094541549682617
self.buckets_partition() spend  sec:  0.47955918312072754
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18816280364990234  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.49451494216919  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.494319438934326  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23121881484985352  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.642219066619873  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.647315979003906  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23645305633544922  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.801616191864014  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.805408000946045  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23044776916503906  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.382045269012451  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.383600234985352  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2285771369934082  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.380969047546387  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.382405757904053  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20116853713989258  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0814592838287354
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.4805457592010498
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.000415802001953125
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.007599592208862305
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4811077117919922
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.6191723346710205
self.buckets_partition() spend  sec:  0.4887349605560303
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18802690505981445  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.463672637939453  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.463465690612793  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23132610321044922  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.649638652801514  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.654735565185547  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2364978790283203  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.832520008087158  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.83631181716919  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23044824600219727  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.383409976959229  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.3850736618042  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22873497009277344  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.38380765914917  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.385230541229248  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20117616653442383  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.066258430480957
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.42435622215270996
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.00040459632873535156
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.007070064544677734
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.42487430572509766
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5622532367706299
self.buckets_partition() spend  sec:  0.43196773529052734
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.1878814697265625  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.474324226379395  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.474160194396973  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2311415672302246  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.648409366607666  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.6535062789917  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23628997802734375  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.800302982330322  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.804094791412354  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23044776916503906  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.370544910430908  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.372044563293457  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22864913940429688  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.38706636428833  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.388928413391113  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20136785507202148  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0677528381347656
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.48731231689453125
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.00045037269592285156
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.007508993148803711
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4879124164581299
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.6265652179718018
self.buckets_partition() spend  sec:  0.4954531192779541
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18808650970458984  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.467402458190918  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.467204093933105  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23134708404541016  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.648274898529053  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.653371810913086  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23636484146118164  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.8453950881958  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.849186897277832  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23070907592773438  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.358213424682617  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.359877109527588  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2286515235900879  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.373512268066406  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.37490701675415  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20122671127319336  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.030468225479126
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.4145348072052002
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0005707740783691406
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.006781101226806641
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4152228832244873
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5525288581848145
self.buckets_partition() spend  sec:  0.42203187942504883
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.1881403923034668  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.468252658843994  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.467999935150146  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23124074935913086  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.648327827453613  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.653424739837646  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23645925521850586  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.796068668365479  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.79986047744751  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23044729232788086  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.379217147827148  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.38088083267212  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22864675521850586  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.384259223937988  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.385642528533936  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20121335983276367  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.960334300994873
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.2956116199493408
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0004055500030517578
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0067446231842041016
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.29619383811950684
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.4337897300720215
self.buckets_partition() spend  sec:  0.302964448928833
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18813657760620117  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.493538856506348  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.493272304534912  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23122024536132812  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.635353088378906  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.640283107757568  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23618507385253906  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.851839065551758  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.855630874633789  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23054742813110352  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.391000747680664  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.392664432525635  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2286510467529297  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.372085094451904  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.373457431793213  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2012009620666504  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.868593692779541
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.41500306129455566
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.00043201446533203125
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0069141387939453125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4156227111816406
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5526092052459717
self.buckets_partition() spend  sec:  0.4225637912750244
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18809890747070312  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.481131076812744  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.480915069580078  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2313084602355957  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.643328666687012  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.648198127746582  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23613405227661133  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.801546573638916  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.805338382720947  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2305459976196289  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.351490020751953  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.353153705596924  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22961950302124023  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.391138553619385  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.392550468444824  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2021803855895996  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.7694733142852783
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.4213829040527344
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0004241466522216797
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.007757425308227539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4219212532043457
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5603880882263184
self.buckets_partition() spend  sec:  0.4297020435333252
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18795299530029297  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.465124607086182  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.4647798538208  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23120832443237305  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.643746852874756  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.648843765258789  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23638677597045898  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.805670261383057  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.809767723083496  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2307138442993164  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.34703540802002  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.34869909286499  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22864246368408203  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.378043174743652  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.379409313201904  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20121335983276367  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.6717662811279297
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.42215466499328613
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.00041604042053222656
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.006937980651855469
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4226820468902588
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5664598941802979
self.buckets_partition() spend  sec:  0.42964649200439453
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18816328048706055  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.527981758117676  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.527850151062012  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2309703826904297  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.631379127502441  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.636476039886475  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23603582382202148  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.858412265777588  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.862509727478027  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2298593521118164  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.384529113769531  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.386182308197021  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22773265838623047  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.368515491485596  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.369956970214844  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20044469833374023  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.6059205532073975
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.4586765766143799
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0004687309265136719
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.00685429573059082
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.45928359031677246
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5958576202392578
self.buckets_partition() spend  sec:  0.4661681652069092
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18806123733520508  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.4800705909729  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.479838848114014  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23116064071655273  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.640171527862549  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.645268440246582  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2363758087158203  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.80033016204834  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.80442762374878  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2307143211364746  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.384641647338867  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.386156558990479  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2286229133605957  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.381042957305908  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.382523536682129  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2012624740600586  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5597338676452637
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.2945556640625
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.00041747093200683594
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.00682520866394043
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.2950878143310547
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.4325432777404785
self.buckets_partition() spend  sec:  0.3019373416900635
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18812847137451172  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.488661766052246  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.488767623901367  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23147344589233398  GigaBytes
Max Memory Allocated: 16.518327236175537  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.65275526046753  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.657852172851562  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2365269660949707  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.807234287261963  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.811331748962402  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23071622848510742  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.345630645751953  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.347141742706299  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22857141494750977  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.375193119049072  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.376601696014404  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2011699676513672  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.4750964641571045
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.4173166751861572
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.000423431396484375
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.006478548049926758
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4178597927093506
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5525202751159668
self.buckets_partition() spend  sec:  0.4243602752685547
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18812847137451172  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.497424602508545  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.49729871749878  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23142576217651367  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.64875841140747  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.653855323791504  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23636245727539062  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.800939559936523  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.804731369018555  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23044919967651367  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.343660831451416  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.345324516296387  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22877264022827148  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.385122776031494  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.38651180267334  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2012186050415039  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.398242712020874
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.4172496795654297
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0004324913024902344
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.006394624710083008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.41779398918151855
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5519654750823975
self.buckets_partition() spend  sec:  0.42421841621398926
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18799638748168945  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.472111701965332  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.471900463104248  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23133039474487305  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.650735855102539  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.655832767486572  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2364063262939453  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.84839916229248  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.852190971374512  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23044824600219727  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.38631534576416  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.387845516204834  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2286233901977539  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.379019737243652  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.380450248718262  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20122814178466797  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.3215513229370117
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.44642138481140137
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0005156993865966797
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.006937503814697266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.44706082344055176
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5840203762054443
self.buckets_partition() spend  sec:  0.4540219306945801
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18805408477783203  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.455873489379883  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.455685138702393  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23134374618530273  GigaBytes
Max Memory Allocated: 16.52056121826172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.652118682861328  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.657050132751465  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23649358749389648  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.853896617889404  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.857688426971436  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23044776916503906  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.337491035461426  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.338965892791748  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22864103317260742  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.390366554260254  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.391847133636475  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2012805938720703  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.248469829559326
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.4624454975128174
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.00042366981506347656
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.00677943229675293
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.46300458908081055
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.6028962135314941
self.buckets_partition() spend  sec:  0.46981287002563477
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18803691864013672  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.466095924377441  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.465821743011475  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23114347457885742  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.632001876831055  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.637083530426025  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2361750602722168  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.85915994644165  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.862951755523682  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2307143211364746  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.37484073638916  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.37650442123413  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2287440299987793  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.373047351837158  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.37448787689209  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20120716094970703  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.1926655769348145
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.2968313694000244
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.0004527568817138672
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.007015705108642578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.29740262031555176
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.43409180641174316
self.buckets_partition() spend  sec:  0.3044426441192627
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18819713592529297  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.497461795806885  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.497170448303223  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23116111755371094  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.638848304748535  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.643784046173096  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2363901138305664  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.799429416656494  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.803221225738525  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23055744171142578  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.333197593688965  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.334712505340576  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22873163223266602  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.396249294281006  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.397672653198242  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20137262344360352  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.14560604095459
the output layer 
self.num_batch (get_in_degree_bucketing) 5
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  5
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  5
G_BUCKET_ID_list [[6, 8, 9, 12, 13], [4, 3, 11, 0, 14], [2, 1, 19, 20, 23, 22], [7, 15, 16, 17, 18, 21], [5, 10]]
Groups_mem_list  [[1881, 1805, 1779, 1591, 1544], [1966, 1929, 1683, 1514, 1508], [1901, 1785, 1326, 1281, 1159, 1148], [1853, 1418, 1415, 1370, 1351, 1144], [1921, 1685]]
G_BUCKET_ID_list length 5
backpack scheduling spend time (sec) 0.42001962661743164
len(g_bucket_nids_list)  5
len(local_split_batches_nid_list)  5
current group_mem  8.602024495220023
current group_mem  8.603722486275078
current group_mem  8.602923641502407
current group_mem  8.554943147503527
current group_mem  3.607020921101766
batches output list generation spend  0.00042247772216796875
self.weights_list  [0.16056564145984759, 0.35284415170275235, 0.27977479904553504, 0.10825700179237088, 0.09855840599949418]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.006402015686035156
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.42055559158325195
num_output  90941
self.output_nids  90941
output nodes length match
global output equals  True
partition total batch output list spend :  0.5563077926635742
self.buckets_partition() spend  sec:  0.42698049545288086
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.18803787231445312  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.466933250427246  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.466665267944336  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2312617301940918  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.641409397125244  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 15.646491050720215  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.23618793487548828  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.834592342376709  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.83838415145874  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.2305455207824707  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.373376846313477  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 14.37489938735962  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.22853469848632812  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.382944583892822  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 10.384366989135742  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.22412109375 GB
    Memory Allocated: 0.20112943649291992  GigaBytes
Max Memory Allocated: 16.520679473876953  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.0848939418792725
epoch_time_list  [7.9047770500183105, 5.3520286083221436, 5.1625189781188965, 5.381871461868286, 5.462913751602173, 5.417553901672363, 5.399550199508667, 5.3553290367126465, 5.192151308059692, 5.336756706237793, 5.414557933807373, 5.384567737579346, 5.363176584243774, 5.276327610015869, 5.318462371826172, 5.329965591430664, 5.462609767913818, 5.4220802783966064, 5.21982741355896, 5.329853534698486]

loading_time list   [0.024750471115112305, 0.06061220169067383, 0.041587114334106445, 0.030472517013549805, 0.041375160217285156, 0.03162574768066406, 0.04450178146362305, 0.027047395706176758, 0.029991865158081055, 0.02447366714477539, 0.02575516700744629, 0.04783487319946289, 0.03003072738647461, 0.026413679122924805, 0.02839827537536621, 0.026428937911987305, 0.03477048873901367, 0.04726243019104004, 0.030499696731567383, 0.026522397994995117]

 data loader gen time  1.4157850742340088
	---backpack schedule time  [0.6175386905670166, 0.5959413051605225, 0.45053768157958984, 0.6193006038665771, 0.6311125755310059, 0.5731081962585449, 0.6361291408538818, 0.5646734237670898, 0.4445810317993164, 0.5618672370910645, 0.5699114799499512, 0.5744791030883789, 0.6086621284484863, 0.4415879249572754, 0.5633025169372559, 0.5606040954589844, 0.5919091701507568, 0.6172797679901123, 0.44643688201904297, 0.5658125877380371]
	---connection_check_time_list  [0.47662854194641113, 0.4563164710998535, 0.4601781368255615, 0.4726266860961914, 0.48720598220825195, 0.49335479736328125, 0.4641284942626953, 0.47765445709228516, 0.4697582721710205, 0.466719388961792, 0.4936196804046631, 0.4725818634033203, 0.4559166431427002, 0.49208831787109375, 0.45995402336120605, 0.45926856994628906, 0.49071240425109863, 0.4599723815917969, 0.4556314945220947, 0.451080322265625]
	---block_gen_time_list  [0.43708062171936035, 0.383347749710083, 0.36208415031433105, 0.3762526512145996, 0.4336252212524414, 0.4272146224975586, 0.3707115650177002, 0.4014284610748291, 0.35647106170654297, 0.3785693645477295, 0.4120204448699951, 0.37071990966796875, 0.35300397872924805, 0.4015688896179199, 0.34392738342285156, 0.3408472537994385, 0.39276838302612305, 0.3613159656524658, 0.3492105007171631, 0.3468341827392578]
training time  [6.29243278503418, 3.800711154937744, 3.7934563159942627, 3.8252084255218506, 3.8155105113983154, 3.832402467727661, 3.829313039779663, 3.830127477645874, 3.836599111557007, 3.849673271179199, 3.8568942546844482, 3.8623692989349365, 3.861259937286377, 3.8607609272003174, 3.8686652183532715, 3.8886427879333496, 3.8966026306152344, 3.88157320022583, 3.8837528228759766, 3.8852779865264893]
---feature block loading time  [0.9205126762390137, 1.1274867057800293, 1.1171090602874756, 1.1438281536102295, 1.1261858940124512, 1.1400926113128662, 1.13499116897583, 1.1333258152008057, 1.1307992935180664, 1.1489710807800293, 1.1407556533813477, 1.13956880569458, 1.1500754356384277, 1.1429994106292725, 1.141331672668457, 1.1572227478027344, 1.1617982387542725, 1.1538026332855225, 1.1554696559906006, 1.1459856033325195]


epoch_time avg   5.355355232954025
loading_time avg   0.03268326818943024
 data loader gen time avg 1.461606651544571
	---backpack schedule time avg 0.559466078877449
	---connection_check_time avg  0.47185294330120087
	---block_gen_time avg  0.3775148242712021
training time  3.858714058995247
---feature block loading time  1.1439609825611115
pure train time per /epoch  [5.366041660308838, 2.440385341644287, 2.44313383102417, 2.4469146728515625, 2.4550204277038574, 2.4573607444763184, 2.457637071609497, 2.461660861968994, 2.470522880554199, 2.464582681655884, 2.4794318675994873, 2.485426664352417, 2.4743072986602783, 2.4803216457366943, 2.4896433353424072, 2.493853807449341, 2.4965031147003174, 2.490107297897339, 2.4894304275512695, 2.500840187072754]
pure train time average  2.4760920580695656
